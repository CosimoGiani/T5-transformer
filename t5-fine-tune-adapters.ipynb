{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"t5-fine-tune-adapters.ipynb","provenance":[],"authorship_tag":"ABX9TyOjhkXGQEBuqhXoMNFuwqix"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## T5 fine-tuning with adapters\n","Here's the implementation for fine-tuning the desidered T5 model but following the **adapters layers** approach. To make the code easier to read, it has been adapted for fine-tuning T5-small for question answering on SQuAD. However with small fixes this code is totally usable for any of the tasks performed in the paper."],"metadata":{"id":"c9ZT5-p2OF1i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDHgRS3UJj-r"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip install --quiet adapter-transformers\n","!pip install --quiet nlp\n","!pip install --quiet tokenizers\n","!pip install --quiet datasets"],"metadata":{"id":"HSO-gRhdJv9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import transformers\n","import nlp\n","from datasets import load_dataset\n","from transformers import T5TokenizerFast as T5Tokenizer"],"metadata":{"id":"C3EiFcxTJzQg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pre-processing\n","First it is loaded the dataset. In order to fine-tune on a task belonging to GLUE or SuperGLUE benchmarks, it also is needed to specify the name of the task, so that the related dataset is loaded correctly."],"metadata":{"id":"EwWm2gEdObna"}},{"cell_type":"code","source":["train_dataset  = load_dataset('squad', split=\"train\")\n","valid_dataset = load_dataset('squad', split=\"validation\")"],"metadata":{"id":"7j9lblBsJ9_d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For this example the prefix is directly specified into the *add_eos_to_example* function. However it is possible to specify the prefix here and later properly add it."],"metadata":{"id":"mtYrPfqbOggO"}},{"cell_type":"code","source":["prefix = \"\"\n","max_input_length = 512\n","max_target_length = 16"],"metadata":{"id":"TtoPBgB9J-3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The example inputs are pre-processed by adding the prefix, elaborating the target text format and inserting the eos (**e**nd **o**f **s**entence) token."],"metadata":{"id":"r2ksiRALOjCr"}},{"cell_type":"code","source":["def add_eos_to_examples(example):\n","    example['input_text'] = 'question: %s  context: %s </s>' % (example['question'], example['context'])\n","    example['target_text'] = '%s </s>' % example['answers']['text'][0]\n","    return example"],"metadata":{"id":"bHUKFIwgKCT8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the tokenizer."],"metadata":{"id":"cI-KaxQxOlcO"}},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained('t5-small')"],"metadata":{"id":"fPi1vVH6J3l4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then the examples are encoded through the tokenizer. This function builds the encodings."],"metadata":{"id":"Kw0R5QK_OoYS"}},{"cell_type":"code","source":["def convert_to_features(example_batch):\n","    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512)\n","    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=16)\n","\n","    encodings = {\n","        'input_ids': input_encodings['input_ids'], \n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids'],\n","        'decoder_attention_mask': target_encodings['attention_mask']\n","    }\n","\n","    return encodings"],"metadata":{"id":"Dg31PrHTKGNe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally the dataset is mapped accordingly leveraging the previous functions."],"metadata":{"id":"mPHYTWzLOrZE"}},{"cell_type":"code","source":["train_dataset = train_dataset.map(add_eos_to_examples)\n","train_dataset = train_dataset.map(convert_to_features, batched=True)\n","valid_dataset = valid_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n","valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)"],"metadata":{"id":"b-WbS-j3KLbj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Remove unused columns."],"metadata":{"id":"0_M0Gg4XOsRK"}},{"cell_type":"code","source":["columns = ['input_ids', 'labels', 'attention_mask', 'decoder_attention_mask']\n","train_dataset.set_format(type='torch', columns=columns)\n","valid_dataset.set_format(type='torch', columns=columns)"],"metadata":{"id":"Sxvcb525KNXv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save the datasets: it will be possible to load them directly during training."],"metadata":{"id":"u35xete9OwJU"}},{"cell_type":"code","source":["torch.save(train_dataset, 'train_data.pt')\n","torch.save(validation_dataset, 'valid_data.pt')"],"metadata":{"id":"bsrMJ99aKPwg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"TUTYvN-qOxzQ"}},{"cell_type":"code","source":["import dataclasses\n","import logging\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Dict, List, Optional\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","import tensorflow as tf\n","import datetime\n","\n","from transformers import T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer, EvalPrediction, AdapterTrainer\n","from transformers import (\n","    HfArgumentParser,\n","    DataCollator,\n","    TrainingArguments,\n","    set_seed,\n",")\n","from transformers import integrations\n","\n","from transformers.adapters import AdapterConfig"],"metadata":{"id":"BY8isjncKSQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger = logging.getLogger(__name__)"],"metadata":{"id":"MKUfa8e4KYfw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build a DataCollator. It takes a list of sample from a Dataset and collates them into a batch. It returns a dictionary of tensors with the keys that the forward method is expecting to receive. This is necessary because the Trainer passes directly this dictionary to the model as argument."],"metadata":{"id":"Rn-qwCj5O04j"}},{"cell_type":"code","source":["@dataclass\n","class T2TDataCollator:\n","\n","    def __call__(self, batch: List) -> Dict[str, torch.Tensor]:\n","\n","        input_ids = torch.stack([example['input_ids'] for example in batch])\n","        labels = torch.stack([example['labels'] for example in batch])\n","        labels[labels[:, :] == 0] = -100\n","        attention_mask = torch.stack([example['attention_mask'] for example in batch])\n","        decoder_attention_mask = torch.stack([example['decoder_attention_mask'] for example in batch])\n","        \n","        return {\n","            'input_ids': input_ids, \n","            'attention_mask': attention_mask,\n","            'labels': labels, \n","            'decoder_attention_mask': decoder_attention_mask\n","        }"],"metadata":{"id":"ikYNT5jsKkpk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Arguments pertaining to which model/config/tokenizer we are going to fine-tune from."],"metadata":{"id":"C6Og6WjvO3r3"}},{"cell_type":"code","source":["@dataclass\n","class ModelArguments:\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n","    )"],"metadata":{"id":"8j4IS1TmKmq_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Arguments pertaining to what data we are going to input our model for training and eval."],"metadata":{"id":"w1bom_ncO6Cj"}},{"cell_type":"code","source":["\n","@dataclass\n","class DataTrainingArguments:\n","\n","    train_file_path: Optional[str] = field(\n","        default='train_data.pt',\n","        metadata={\"help\": \"Path for cached train dataset\"},\n","    )\n","    valid_file_path: Optional[str] = field(\n","        default='valid_data.pt',\n","        metadata={\"help\": \"Path for cached valid dataset\"},\n","    )\n","    max_len: Optional[int] = field(\n","        default=max_input_length,\n","        metadata={\"help\": \"Max input length for the source text\"},\n","    )\n","    target_max_len: Optional[int] = field(\n","        default=max_target_length,\n","        metadata={\"help\": \"Max input length for the target text\"},\n","    )"],"metadata":{"id":"3DZQZoswKn5h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following steps differ from the implementation of fine-tuning T5 with a standard approach. First it is loaded the configuration for the adapter. Notice the main hyperparameter is the **reduction factor**, which can be manipulated and changed accordingly to obtain the desired inner dimension of the adapter *d*. Following the experiments in the paper, the tested values of *d* are: 32, 128, 512 and 2048. To obtain such values for the T5-small the reduction factor values should be: 64, 16, 4 and 1."],"metadata":{"id":"QXafyLxxPo83"}},{"cell_type":"code","source":["config = AdapterConfig(mh_adapter=True, output_adapter=True, reduction_factor=64, non_linearity=\"relu\")"],"metadata":{"id":"FI1DIN5rKt2T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The model is loaded."],"metadata":{"id":"_teH950HULgK"}},{"cell_type":"code","source":["model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"],"metadata":{"id":"IlG3quB3LRMJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then the adapter layer is added to the model."],"metadata":{"id":"TKr-705TUNG8"}},{"cell_type":"code","source":["model.add_adapter(\"bottleneck_adapter\", config=config)"],"metadata":{"id":"7tAlO3whLRjx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And all the model's parameters are freezed, so during the training only the adapter ones are effectively trained."],"metadata":{"id":"jvwmVrmrURGf"}},{"cell_type":"code","source":["model.train_adapter(\"bottleneck_adapter\")"],"metadata":{"id":"vbulWaprLS0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.set_active_adapters(\"bottleneck_adapter\")"],"metadata":{"id":"Wk7Ov24MLV2Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main function which contains the code to effectively fine-tune the pre-trained model."],"metadata":{"id":"apT6g9K2PoEj"}},{"cell_type":"code","source":["def main():\n","\n","    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n","\n","    model_args, data_args = parser.parse_json_file(json_file=os.path.abspath('args.json'))\n","\n","    training_args = TrainingArguments(\n","        learning_rate=1e-4,\n","        num_train_epochs=5,\n","        per_device_train_batch_size=32,\n","        per_device_eval_batch_size=32,\n","        logging_steps=1000,\n","        logging_first_step=True,\n","        output_dir='./models/gpu',\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=True,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=1000,\n","        prediction_loss_only = True,\n","        optim=\"adafactor\"\n","    )\n","\n","    if (\n","        os.path.exists(training_args.output_dir)\n","        and os.listdir(training_args.output_dir)\n","        and training_args.do_train\n","        and not training_args.overwrite_output_dir\n","    ):\n","        raise ValueError(\n","            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n","        )\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.info(\"Training/evaluation parameters %s\", training_args)\n","\n","    # Set seed\n","    set_seed(training_args.seed)\n","\n","    # Get datasets\n","    print('Loading data...')\n","    train_dataset  = torch.load(data_args.train_file_path)\n","    valid_dataset = torch.load(data_args.valid_file_path)\n","    print('Loading done!')\n","\n","    # Initialize the Trainer\n","    trainer = AdapterTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=valid_dataset,\n","        data_collator=T2TDataCollator(),\n","    )\n","\n","    # Training\n","    if training_args.do_train:\n","        trainer.train(\n","            resume_from_checkpoint=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n","        )\n","\n","    # Evaluation\n","    results = {}\n","    if training_args.do_eval and training_args.local_rank in [-1, 0]:\n","        logger.info(\"*** Evaluate ***\")\n","\n","        eval_output = trainer.evaluate()\n","\n","        output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n","        logger.info(\"***** Eval results *****\")\n","          for key in sorted(eval_output.keys()):\n","              logger.info(\"  %s = %s\", key, str(eval_output[key]))\n","              results.update(eval_output)\n","    \n","    return results"],"metadata":{"id":"4YNgEHPCLa9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load TensorBoard to monitor the training performance. For fine-tuning sake this step is not necessary, but always useful."],"metadata":{"id":"q3XJ-z6pUcb_"}},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"sRJcJUoUMID6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensorboard --logdir ./models/gpu/runs"],"metadata":{"id":"cKJenUlDMKLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"Z-5Aq7H4ML1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args_dict = {\n","  \"model_name_or_path\": 't5-small',\n","  \"max_len\": max_input_length ,\n","  \"target_max_len\": max_target_length,\n","  \"output_dir\": './models/gpu',\n","  \"overwrite_output_dir\": True,\n","  \"per_device_train_batch_size\": 32,\n","  \"per_device_eval_batch_size\": 32,\n","  \"learning_rate\": 1e-4,\n","  \"num_train_epochs\": 5,\n","  \"optim\":\"adafactor\",\n","  \"do_train\": True,\n","}"],"metadata":{"id":"ISLsymJFMOBW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('args.json', 'w') as f:\n","  json.dump(args_dict, f)"],"metadata":{"id":"2z6J0s1CNMlP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"id":"G6v-WRjnNNFN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The AdapterTrainer class does not have a *save_model* method. For this reason the model and the adapter are then saved manually to be used for inference later."],"metadata":{"id":"ulhqeggVUj_y"}},{"cell_type":"code","source":["model.save_pretrained('/content/models/gpu/')"],"metadata":{"id":"Dbh-et63Nb05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_adapter('/content/models/gpu/', 'bottleneck_adapter', with_head=True)"],"metadata":{"id":"XHcH3SzyNc9S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluation\n","After having fine-tuned the model, it can be used to generate the predictions. As stated in the T5 paper, since the SQuAD test dataset coincides with the validation dataset, here is reported the evaluation process. However, the GLUE and SuperGLUE tasks have to be evaluated on the related servers."],"metadata":{"id":"jlYutmrnUiMs"}},{"cell_type":"code","source":["import nlp\n","import pickle\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","from tqdm.auto import tqdm\n","import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","import re\n","from itertools import chain\n","from string import punctuation\n","from sklearn import metrics\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","from transformers.adapters import AutoAdapterModel\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"ydnlPE1DNinn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the model."],"metadata":{"id":"3oZH7jwlUyhz"}},{"cell_type":"code","source":["model = T5ForConditionalGeneration.from_pretrained('/content/models/gpu/')"],"metadata":{"id":"qE7JnH3YNrd0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the adapter."],"metadata":{"id":"9UcwC6BYUzS7"}},{"cell_type":"code","source":["model.load_adapter('/content/models/gpu/')"],"metadata":{"id":"vpeAgQkZNw62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is the dataset for the evaluation."],"metadata":{"id":"bxA976viU6IG"}},{"cell_type":"code","source":["test_dataset = torch.load('valid_data.pt')\n","dataloader = DataLoader(test_dataset, batch_size=32)"],"metadata":{"id":"tyhUN7Z4N4KQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.set_active_adapters(\"bottleneck_adapter\")"],"metadata":{"id":"Jc9TJl2DN5uo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate the predictions."],"metadata":{"id":"zsAUKRAjU8Qz"}},{"cell_type":"code","source":["answers = []\n","for batch in tqdm(dataloader):\n","  outs = model.generate(input_ids=batch['input_ids'], \n","                        attention_mask=batch['attention_mask'],\n","                        max_length=16)\n","  outs = [tokenizer.decode(ids) for ids in outs]\n","  answers.extend(outs)"],"metadata":{"id":"JXQrLVumN6Eq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Retrieve the predictions (with some clean-up):"],"metadata":{"id":"klXI4lQ3U-3_"}},{"cell_type":"code","source":["predictions = []\n","for preds in answers:\n","  pred = preds.replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n","  predictions.append(pred[1:])"],"metadata":{"id":"nLqUf_8XN-wK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And these are the references, i.e. the ground truth."],"metadata":{"id":"ctLZ21_JVD9f"}},{"cell_type":"code","source":["references = []\n","for refs in valid_dataset[\"answers\"]:\n","  references.append(refs[\"text\"])"],"metadata":{"id":"Lc9B0UgbN_yX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The last step for evaluating our fine-tuned model is to validate the predictions and the references using the metric referring to the task performed.\n"],"metadata":{"id":"cDVEQJAdVGML"}}]}